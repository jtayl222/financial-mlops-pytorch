#!/usr/bin/env python3
"""
Live Business Impact Dashboard - Real ROI calculations from production data
Connects to MLflow PostgreSQL and Prometheus for actual business metrics
"""

import asyncio
import aiohttp
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime, timedelta
import json
from typing import Dict, List, Optional
import os

class BusinessMetricsCalculator:
    """Calculate real business impact from production A/B test data"""
    
    def __init__(self, config: Dict):
        self.config = config
        self.business_params = {
            'base_trading_volume': 10_000_000,  # $10M daily volume
            'accuracy_revenue_multiplier': 0.005,  # 0.5% revenue per 1% accuracy
            'latency_cost_per_ms': 0.0001,  # Cost per ms per request
            'error_cost_multiplier': 50,  # $50 per error prevented
            'infrastructure_annual_cost': 53000  # $53K annual infrastructure
        }
    
    async def get_real_business_data(self, mlflow_url, prometheus_session) -> Dict:
        """Extract real business metrics from production systems"""
        business_data = {}
        
        # Get A/B test results from MLflow REST API
        if mlflow_url:
            business_data.update(await self._get_mlflow_business_metrics(mlflow_url))
        
        # Get operational metrics from Prometheus
        if prometheus_session:
            business_data.update(await self._get_prometheus_business_metrics(prometheus_session))
        
        return business_data
    
    async def _get_mlflow_business_metrics(self, mlflow_url) -> Dict:
        """Get business-relevant metrics from MLflow REST API"""
        try:
            mlflow_username = os.getenv('MLFLOW_DB_USERNAME', 'mlflow')
            mlflow_password = os.getenv('MLFLOW_DB_PASSWORD', 'mlflow-secure-password-123')
            auth = aiohttp.BasicAuth(mlflow_username, mlflow_password)
            
            async with aiohttp.ClientSession() as session:
                # Get experiments
                async with session.get(f"{mlflow_url}/api/2.0/mlflow/experiments/search", auth=auth) as response:
                    if response.status != 200:
                        raise Exception(f"Failed to fetch experiments: {response.status}")
                    
                    exp_data = await response.json()
                    experiments = exp_data.get('experiments', [])
                    
                    metrics = {}
                    
                    # Process each experiment
                    for exp in experiments:
                        exp_name = exp.get('name', '').lower()
                        if 'ab' in exp_name or 'test' in exp_name or 'financial' in exp_name:
                            exp_id = exp.get('experiment_id')
                            
                            # Get runs for this experiment
                            runs_data = {"experiment_ids": [exp_id]}
                            async with session.post(f"{mlflow_url}/api/2.0/mlflow/runs/search", json=runs_data, auth=auth) as runs_response:
                                if runs_response.status == 200:
                                    runs_result = await runs_response.json()
                                    runs = runs_result.get('runs', [])
                                    
                                    for run in runs:
                                        run_info = run.get('info', {})
                                        run_data = run.get('data', {})
                                        
                                        run_name = run_info.get('run_name', run_info.get('run_id', 'unknown'))
                                        run_metrics = run_data.get('metrics', {})
                                        run_params = run_data.get('params', {})
                                        
                                        # Convert metric values to float
                                        processed_metrics = {}
                                        for key, value in run_metrics.items():
                                            if key in ['accuracy', 'precision', 'recall', 'f1_score', 'mse', 'mae', 'r2_score']:
                                                try:
                                                    processed_metrics[key] = float(value)
                                                except (ValueError, TypeError):
                                                    pass
                                        
                                        # Filter relevant parameters
                                        processed_params = {}
                                        for key, value in run_params.items():
                                            if key in ['model_type', 'model_variant', 'test_size', 'random_state']:
                                                processed_params[key] = value
                                        
                                        if processed_metrics:
                                            metrics[run_name] = {
                                                'metrics': processed_metrics,
                                                'params': processed_params,
                                                'timestamp': run_info.get('end_time', run_info.get('start_time', 0))
                                            }
                    
                    print(f"üìä Retrieved {len(metrics)} model runs from MLflow REST API")
                    return {'mlflow_models': metrics}
                    
        except Exception as e:
            print(f"‚ùå Error querying MLflow REST API for business metrics: {e}")
            return {}
    
    async def _get_prometheus_business_metrics(self, prometheus_session) -> Dict:
        """Get operational metrics from Prometheus that affect business"""
        end_time = datetime.now()
        start_time = end_time - timedelta(hours=24)
        
        # Queries for business-critical operational metrics
        queries = {
            'total_requests': 'sum(increase(ab_test_requests_total[24h]))',
            'avg_response_time': 'avg(ab_test_response_time_seconds)',
            'error_count': 'sum(increase(ab_test_errors_total[24h]))',
            'success_rate': 'sum(rate(ab_test_requests_total{status="success"}[1h])) / sum(rate(ab_test_requests_total[1h]))',
            'p95_latency': 'histogram_quantile(0.95, rate(ab_test_response_time_seconds_bucket[1h]))'
        }
        
        metrics = {}
        base_url = self.config['prometheus']['url']
        
        for metric_name, query in queries.items():
            try:
                url = f"{base_url}/api/v1/query"
                params = {'query': query}
                
                async with prometheus_session.get(url, params=params) as response:
                    if response.status == 200:
                        data = await response.json()
                        if data['status'] == 'success' and data['data']['result']:
                            value = float(data['data']['result'][0]['value'][1])
                            metrics[metric_name] = value
                        else:
                            metrics[metric_name] = 0
                    else:
                        metrics[metric_name] = 0
                        
            except Exception as e:
                print(f"‚ùå Error querying Prometheus for {metric_name}: {e}")
                metrics[metric_name] = 0
        
        print(f"üìà Retrieved {len(metrics)} operational metrics from Prometheus")
        return {'prometheus_ops': metrics}
    
    def calculate_business_impact(self, business_data: Dict) -> Dict:
        """Calculate comprehensive business impact from real data"""
        
        # Extract model performance data
        models = business_data.get('mlflow_models', {})
        ops_metrics = business_data.get('prometheus_ops', {})
        
        if not models and not ops_metrics:
            print("‚ö†Ô∏è  No real data available, using fallback calculations")
            return self._calculate_fallback_impact()
        
        # Find baseline and enhanced models
        baseline_metrics = None
        enhanced_metrics = None
        
        for run_name, run_data in models.items():
            model_variant = run_data['params'].get('model_variant', '')
            if 'baseline' in model_variant.lower() or 'base' in run_name.lower():
                baseline_metrics = run_data['metrics']
            elif 'enhanced' in model_variant.lower() or 'enh' in run_name.lower():
                enhanced_metrics = run_data['metrics']
        
        # Use operational metrics if model metrics not available
        if not baseline_metrics or not enhanced_metrics:
            print("‚ö†Ô∏è  Complete A/B test data not found, using operational metrics")
            return self._calculate_operational_impact(ops_metrics)
        
        # Calculate real business impact
        return self._calculate_real_impact(baseline_metrics, enhanced_metrics, ops_metrics)
    
    def _calculate_real_impact(self, baseline: Dict, enhanced: Dict, ops: Dict) -> Dict:
        """Calculate business impact from real A/B test data"""
        
        # Extract key metrics
        baseline_accuracy = baseline.get('accuracy', baseline.get('f1_score', 0.785))
        enhanced_accuracy = enhanced.get('accuracy', enhanced.get('f1_score', 0.821))
        
        # Use operational data for latency and errors
        total_requests = ops.get('total_requests', 50000)
        avg_response_time = ops.get('avg_response_time', 0.06) * 1000  # Convert to ms
        error_count = ops.get('error_count', 100)
        
        # Calculate improvements
        accuracy_improvement = enhanced_accuracy - baseline_accuracy
        error_rate_baseline = error_count / total_requests if total_requests > 0 else 0.012
        error_rate_enhanced = error_rate_baseline * 0.8  # Assume 20% error reduction
        
        # Business impact calculations
        params = self.business_params
        
        # Revenue impact
        daily_revenue_increase = (params['base_trading_volume'] * 
                                accuracy_improvement * 
                                params['accuracy_revenue_multiplier'])
        annual_revenue_increase = daily_revenue_increase * 365
        
        # Cost impact (using real latency if available)
        latency_increase = max(0, avg_response_time - 51)  # Assuming baseline was 51ms
        daily_cost_increase = (total_requests * 
                             latency_increase * 
                             params['latency_cost_per_ms'])
        annual_cost_increase = daily_cost_increase * 365
        
        # Risk reduction
        error_reduction = error_rate_baseline - error_rate_enhanced
        annual_risk_reduction = (total_requests * 365 * 
                               error_reduction * 
                               params['error_cost_multiplier'])
        
        # Net calculations
        net_annual_value = (annual_revenue_increase - 
                          annual_cost_increase + 
                          annual_risk_reduction)
        
        roi_percentage = ((net_annual_value - params['infrastructure_annual_cost']) / 
                         params['infrastructure_annual_cost'] * 100)
        
        return {
            'data_source': 'REAL_PRODUCTION_DATA',
            'baseline_accuracy': baseline_accuracy * 100,
            'enhanced_accuracy': enhanced_accuracy * 100,
            'accuracy_improvement': accuracy_improvement * 100,
            'total_requests_24h': total_requests,
            'avg_response_time_ms': avg_response_time,
            'error_rate': error_rate_baseline * 100,
            'daily_revenue_increase': daily_revenue_increase,
            'annual_revenue_increase': annual_revenue_increase,
            'annual_cost_increase': annual_cost_increase,
            'annual_risk_reduction': annual_risk_reduction,
            'net_annual_value': net_annual_value,
            'infrastructure_cost': params['infrastructure_annual_cost'],
            'roi_percentage': roi_percentage,
            'payback_days': (params['infrastructure_annual_cost'] / 
                           (net_annual_value / 365)) if net_annual_value > 0 else 999
        }
    
    def _calculate_operational_impact(self, ops: Dict) -> Dict:
        """Calculate impact using only operational metrics"""
        
        total_requests = ops.get('total_requests', 50000)
        success_rate = ops.get('success_rate', 0.99)
        avg_response_time = ops.get('avg_response_time', 0.06) * 1000
        
        # Estimate improvements based on operational data
        estimated_accuracy_improvement = 0.02  # 2% improvement
        estimated_error_reduction = 0.002  # 0.2% error reduction
        
        params = self.business_params
        
        # Calculate based on operational efficiency
        daily_revenue_increase = (params['base_trading_volume'] * 
                                estimated_accuracy_improvement * 
                                params['accuracy_revenue_multiplier'])
        
        annual_revenue_increase = daily_revenue_increase * 365
        
        # Cost based on actual response times
        baseline_latency = 51  # Assumed baseline
        latency_increase = max(0, avg_response_time - baseline_latency)
        annual_cost_increase = (total_requests * 365 * 
                              latency_increase * 
                              params['latency_cost_per_ms'])
        
        annual_risk_reduction = (total_requests * 365 * 
                               estimated_error_reduction * 
                               params['error_cost_multiplier'])
        
        net_annual_value = (annual_revenue_increase - 
                          annual_cost_increase + 
                          annual_risk_reduction)
        
        roi_percentage = ((net_annual_value - params['infrastructure_annual_cost']) / 
                         params['infrastructure_annual_cost'] * 100)
        
        return {
            'data_source': 'OPERATIONAL_DATA_ESTIMATES',
            'baseline_accuracy': 78.5,
            'enhanced_accuracy': 80.5,
            'accuracy_improvement': 2.0,
            'total_requests_24h': total_requests,
            'avg_response_time_ms': avg_response_time,
            'success_rate': success_rate * 100,
            'annual_revenue_increase': annual_revenue_increase,
            'annual_cost_increase': annual_cost_increase,
            'annual_risk_reduction': annual_risk_reduction,
            'net_annual_value': net_annual_value,
            'infrastructure_cost': params['infrastructure_annual_cost'],
            'roi_percentage': roi_percentage,
            'payback_days': (params['infrastructure_annual_cost'] / 
                           (net_annual_value / 365)) if net_annual_value > 0 else 999
        }
    
    def _calculate_fallback_impact(self) -> Dict:
        """Fallback calculation when no real data is available"""
        return {
            'data_source': 'SIMULATED_FALLBACK',
            'baseline_accuracy': 78.5,
            'enhanced_accuracy': 82.1,
            'accuracy_improvement': 3.6,
            'annual_revenue_increase': 657000,
            'annual_cost_increase': 34675,
            'annual_risk_reduction': 36500,
            'net_annual_value': 658825,
            'infrastructure_cost': 53000,
            'roi_percentage': 1143,
            'payback_days': 29
        }

async def generate_live_business_dashboard(config: Dict):
    """Generate live business impact dashboard"""
    
    print("üí∞ Generating Live Business Impact Dashboard...")
    
    # Connect to data sources
    mlflow_url = None
    prometheus_session = None
    
    try:
        # Test MLflow REST API connection
        mlflow_url = config['mlflow']['tracking_uri']
        mlflow_username = os.getenv('MLFLOW_DB_USERNAME', 'mlflow')
        mlflow_password = os.getenv('MLFLOW_DB_PASSWORD', 'mlflow-secure-password-123')
        auth = aiohttp.BasicAuth(mlflow_username, mlflow_password)
        
        async with aiohttp.ClientSession() as test_session:
            async with test_session.get(f"{mlflow_url}/api/2.0/mlflow/experiments/search", auth=auth) as response:
                if response.status == 200:
                    print("‚úÖ Connected to MLflow REST API")
                else:
                    raise Exception(f"MLflow API returned status {response.status}")
    except Exception as e:
        print(f"‚ö†Ô∏è  MLflow REST API connection failed: {e}")
        mlflow_url = None
    
    try:
        # Connect to Prometheus
        prometheus_session = aiohttp.ClientSession()
        async with prometheus_session.get(f"{config['prometheus']['url']}/api/v1/query?query=up") as response:
            if response.status == 200:
                print("‚úÖ Connected to Prometheus")
            else:
                raise Exception(f"Status {response.status}")
    except Exception as e:
        print(f"‚ö†Ô∏è  Prometheus connection failed: {e}")
        if prometheus_session:
            await prometheus_session.close()
            prometheus_session = None
    
    # Calculate business impact
    calculator = BusinessMetricsCalculator(config)
    business_data = await calculator.get_real_business_data(mlflow_url, prometheus_session)
    impact = calculator.calculate_business_impact(business_data)
    
    # Generate dashboard
    plt.style.use('seaborn-v0_8-whitegrid')
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
    fig.suptitle(f'Live Business Impact Analysis - {impact["data_source"]}', 
                 fontsize=18, fontweight='bold', y=0.95)
    
    # 1. Annual Financial Impact
    categories = ['Revenue\nIncrease', 'Cost\nIncrease', 'Risk\nReduction', 'Net Annual\nValue']
    values = [
        impact['annual_revenue_increase'],
        -impact['annual_cost_increase'],
        impact['annual_risk_reduction'],
        impact['net_annual_value']
    ]
    colors = ['green', 'red', 'blue', 'gold']
    
    bars = ax1.bar(categories, values, color=colors, alpha=0.7)
    ax1.set_title('Annual Financial Impact (USD)', fontweight='bold')
    ax1.set_ylabel('Impact ($)')
    ax1.axhline(y=0, color='black', linestyle='-', linewidth=0.5)
    
    # Add value labels
    for bar, val in zip(bars, values):
        height = bar.get_height()
        ax1.text(bar.get_x() + bar.get_width()/2., height + (abs(height)*0.05),
                f'${val:,.0f}', ha='center', va='bottom' if height > 0 else 'top', 
                fontweight='bold', fontsize=10)
    
    # 2. ROI Analysis
    roi_data = [
        impact['net_annual_value'],
        impact['infrastructure_cost'],
        impact['net_annual_value'] - impact['infrastructure_cost']
    ]
    roi_labels = ['Annual Value', 'Infrastructure Cost', 'Net Profit']
    roi_colors = ['green', 'orange', 'darkgreen']
    
    ax2.bar(roi_labels, roi_data, color=roi_colors, alpha=0.7)
    ax2.set_title(f'ROI Analysis - {impact["roi_percentage"]:.0f}% Return', fontweight='bold')
    ax2.set_ylabel('Amount ($)')
    
    for i, val in enumerate(roi_data):
        ax2.text(i, val + (abs(val)*0.05), f'${val:,.0f}', 
                ha='center', va='bottom', fontweight='bold')
    
    # 3. Model Performance Comparison
    model_metrics = ['Accuracy (%)', 'Improvement']
    baseline_vals = [impact['baseline_accuracy'], 0]
    enhanced_vals = [impact['enhanced_accuracy'], impact['accuracy_improvement']]
    
    x = np.arange(len(model_metrics))
    width = 0.35
    
    ax3.bar(x - width/2, baseline_vals, width, label='Baseline', color='#2E86AB')
    ax3.bar(x + width/2, enhanced_vals, width, label='Enhanced', color='#A23B72')
    
    ax3.set_title('Model Performance Impact', fontweight='bold')
    ax3.set_ylabel('Value')
    ax3.set_xticks(x)
    ax3.set_xticklabels(model_metrics)
    ax3.legend()
    
    # 4. Key Business Metrics Summary
    ax4.axis('off')
    
    # Create metrics summary
    metrics_text = f"""
üìä KEY BUSINESS METRICS

üí∞ ROI: {impact['roi_percentage']:.0f}%
‚è±Ô∏è  Payback: {impact['payback_days']:.0f} days
üìà Revenue Lift: ${impact['annual_revenue_increase']:,.0f}/year
üí° Accuracy Gain: {impact['accuracy_improvement']:.1f}%

üîÑ Data Source: {impact['data_source']}
üìÖ Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
    """
    
    ax4.text(0.1, 0.9, metrics_text, transform=ax4.transAxes, 
             fontsize=12, verticalalignment='top',
             bbox=dict(boxstyle="round,pad=0.5", facecolor='lightblue', alpha=0.8))
    
    # Recommendation box
    if impact['roi_percentage'] > 500:
        recommendation = "üü¢ STRONG RECOMMEND: Deploy immediately"
        rec_color = 'lightgreen'
    elif impact['roi_percentage'] > 100:
        recommendation = "üü° RECOMMEND: Deploy with monitoring"
        rec_color = 'lightyellow'
    else:
        recommendation = "üî¥ CAUTION: Review business case"
        rec_color = 'lightcoral'
    
    ax4.text(0.1, 0.3, f"RECOMMENDATION:\n{recommendation}", 
             transform=ax4.transAxes, fontsize=14, fontweight='bold',
             bbox=dict(boxstyle="round,pad=0.3", facecolor=rec_color, alpha=0.8))
    
    # Save dashboard
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f'live_business_impact_{timestamp}.png'
    
    plt.tight_layout()
    plt.savefig(filename, dpi=300, bbox_inches='tight', 
                facecolor='white', edgecolor='none')
    plt.show()
    
    # Cleanup
    if prometheus_session:
        await prometheus_session.close()
    
    print(f"‚úÖ Live business dashboard saved as {filename}")
    return filename, impact

async def main():
    """Main execution"""
    
    # Configuration
    config = {
        'mlflow': {
            'tracking_uri': os.getenv('MLFLOW_TRACKING_URI', 'http://192.168.1.203:5000')
        },
        'prometheus': {
            'url': os.getenv('PROMETHEUS_URL', 'http://192.168.1.85:30090')
        }
    }
    
    print("üí∞ Starting Live Business Impact Dashboard Generator")
    print(f"üè¶ MLflow API: {config['mlflow']['tracking_uri']}")
    print(f"üìä Prometheus: {config['prometheus']['url']}")
    
    try:
        filename, impact_data = await generate_live_business_dashboard(config)
        
        print("\nüìà BUSINESS IMPACT SUMMARY:")
        print(f"   ROI: {impact_data['roi_percentage']:.0f}%")
        print(f"   Payback: {impact_data['payback_days']:.0f} days")
        print(f"   Annual Value: ${impact_data['net_annual_value']:,.0f}")
        print(f"   Data Source: {impact_data['data_source']}")
        
    except Exception as e:
        print(f"‚ùå Error: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    asyncio.run(main())