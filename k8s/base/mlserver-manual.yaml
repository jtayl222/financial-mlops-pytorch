---
apiVersion: v1
kind: ConfigMap
metadata:
  name: seldon-agent
  namespace: financial-ml
  labels:
    app.kubernetes.io/name: financial-mlops-pytorch
    app.kubernetes.io/part-of: ml-platform
    app.kubernetes.io/managed-by: kustomize
data:
  agent.yaml: |
    rclone:
      config_secrets: []
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: seldon-tracing
  namespace: financial-ml
  labels:
    app.kubernetes.io/name: financial-mlops-pytorch
    app.kubernetes.io/part-of: ml-platform
    app.kubernetes.io/managed-by: kustomize
data:
  tracing.json: |
    {
      "service_name": "mlserver",
      "endpoint": "",
      "ratio": 1.0,
      "type": "JAEGER"
    }
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: mlserver
  namespace: financial-ml
  labels:
    app.kubernetes.io/name: financial-mlops-pytorch
    app.kubernetes.io/part-of: ml-platform
    app.kubernetes.io/managed-by: kustomize
spec:
  serviceName: mlserver
  replicas: 1
  selector:
    matchLabels:
      seldon-server-name: mlserver
  template:
    metadata:
      labels:
        seldon-server-name: mlserver
        app.kubernetes.io/name: financial-mlops-pytorch
        app.kubernetes.io/part-of: ml-platform
        app.kubernetes.io/managed-by: kustomize
    spec:
      serviceAccountName: default
      containers:
      - name: rclone
        image: docker.io/seldonio/seldon-rclone:2.9.0
        ports:
        - containerPort: 5572
          name: rclone
        resources:
          requests:
            cpu: 50m
            memory: 128Mi
          limits:
            cpu: 100m
            memory: 128Mi
        env:
        - name: RCLONE_LOG_LEVEL
          value: "INFO"
        volumeMounts:
        - name: mlserver-models
          mountPath: /mnt/agent
        readinessProbe:
          tcpSocket:
            port: 5572
          initialDelaySeconds: 5
          periodSeconds: 5
      
      - name: agent
        image: seldon-agent:2.9.0-fixed-v2
        imagePullPolicy: Never
        ports:
        - containerPort: 9501
          name: agent-grpc
        - containerPort: 9001
          name: agent-http
        - containerPort: 9006
          name: metrics
        resources:
          requests:
            cpu: 200m
            memory: 1Gi
          limits:
            cpu: 500m
            memory: 1Gi
        env:
        - name: SELDON_SERVER_CAPABILITIES
          value: "mlserver,alibi-detect,alibi-explain,huggingface,lightgbm,mlflow,python,sklearn,spark-mlib,xgboost"
        - name: SELDON_LOG_LEVEL
          value: "info"
        - name: SELDON_SERVER_HTTP_PORT
          value: "9000"
        - name: SELDON_SERVER_GRPC_PORT
          value: "9500"
        - name: SELDON_SERVER_HOST
          value: "127.0.0.1"
        - name: MLSERVER_GRPC_ENDPOINT
          value: "localhost:9500"
        - name: SELDON_REVERSE_PROXY_HTTP_PORT
          value: "9001"
        - name: SELDON_REVERSE_PROXY_GRPC_PORT
          value: "9501"
        - name: SELDON_SCHEDULER_HOST
          value: "seldon-scheduler"
        - name: SELDON_SCHEDULER_PORT
          value: "9005"
        - name: SELDON_METRICS_PORT
          value: "9006"
        - name: SELDON_SERVER_TYPE
          value: "mlserver"
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: POD_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: MEMORY_REQUEST
          valueFrom:
            resourceFieldRef:
              resource: requests.memory
        volumeMounts:
        - name: mlserver-models
          mountPath: /mnt/agent
        - name: config-volume
          mountPath: /mnt/config
        - name: tracing-config-volume
          mountPath: /mnt/tracing

      - name: mlserver
        image: docker.io/seldonio/mlserver:1.6.1
        ports:
        - containerPort: 9500
          name: server-grpc
        - containerPort: 9000
          name: server-http
        resources:
          requests:
            cpu: 100m
            memory: 1Gi
          limits:
            cpu: 500m
            memory: 1Gi
        env:
        - name: MLSERVER_HOST
          value: "127.0.0.1"
        - name: MLSERVER_HTTP_PORT
          value: "9000"
        - name: MLSERVER_GRPC_PORT
          value: "9500"
        - name: MLSERVER_MODELS_DIR
          value: "/mnt/agent/models"
        - name: MLSERVER_MODEL_PARALLEL_WORKERS
          value: "1"
        - name: MLSERVER_LOAD_MODELS_AT_STARTUP
          value: "false"
        - name: MLSERVER_GRPC_MAX_MESSAGE_LENGTH
          value: "1048576000"
        volumeMounts:
        - name: mlserver-models
          mountPath: /mnt/agent
          readOnly: true
        livenessProbe:
          httpGet:
            path: /v2/health/live
            port: server-http
          periodSeconds: 10
          failureThreshold: 3
        readinessProbe:
          httpGet:
            path: /v2/health/live
            port: server-http
          initialDelaySeconds: 5
          periodSeconds: 5
          failureThreshold: 3
        startupProbe:
          httpGet:
            path: /v2/health/live
            port: server-http
          periodSeconds: 10
          failureThreshold: 10
      volumes:
      - name: config-volume
        configMap:
          name: seldon-agent
      - name: tracing-config-volume
        configMap:
          name: seldon-tracing
  volumeClaimTemplates:
  - metadata:
      name: mlserver-models
    spec:
      accessModes: ["ReadWriteOnce"]
      resources:
        requests:
          storage: 1Gi
---
apiVersion: v1
kind: Service
metadata:
  name: mlserver
  namespace: financial-ml
  labels:
    app.kubernetes.io/name: financial-mlops-pytorch
    app.kubernetes.io/part-of: ml-platform
    app.kubernetes.io/managed-by: kustomize
spec:
  selector:
    seldon-server-name: mlserver
  ports:
  - name: server-grpc
    port: 9500
    targetPort: 9500
  - name: server-http
    port: 9000
    targetPort: 9000
  - name: agent-grpc
    port: 9501
    targetPort: 9501
  - name: agent-http
    port: 9001
    targetPort: 9001
  - name: metrics
    port: 9006
    targetPort: 9006